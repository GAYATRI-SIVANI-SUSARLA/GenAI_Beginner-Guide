{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/zjhKtSdusuukxrjvGxEA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GAYATRI-SIVANI-SUSARLA/GenAI_Beginner-Guide/blob/main/Bert_Textclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl7FSiwub0QX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.nn.functional import softmax\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##loading pre-trained bert tokenizer and model for sequence classification\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "##function to classify sentiment\n",
        "def classify_sentiment(text):\n",
        "  #Tokenize the input text\n",
        "  input = tokenizer(text, return_tensors = \"pt\", truncation = True, padding = True, max_length = 512)\n",
        "\n",
        "  ## Get model with predictions\n",
        "  with torch.no_grad():\n",
        "    output = model(**input)\n",
        "    logit = output.logits\n",
        "\n",
        "    ## convert logits to probabilities using SOFTMAX\n",
        "    prob = softmax(logit, dim = -1)\n",
        "\n",
        "    ## get predicted class\n",
        "    predicted_class = torch.argmax(prob, dim = -1).item()\n",
        "\n",
        "    ## Mapping model output to sentiment labels\n",
        "    if predicted_class == 1:\n",
        "      sentiment = \"Happy\"\n",
        "\n",
        "    else:\n",
        "      sentiment = \"Sad\"\n",
        "\n",
        "    return sentiment, prob\n",
        "\n",
        "## Example Text\n",
        "sentence = \"i am excited learning about large language models\"\n",
        "\n",
        "## classify sentiment\n",
        "sentiment, probabilities = classify_sentiment(sentence)\n",
        "\n",
        "print(f\"Sentence: {sentence}\")\n",
        "print(f\"Sentiment: {sentiment}\")\n",
        "print(f\"Probabilities: {probabilities}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjWBGHP-f13Y",
        "outputId": "31655791-b6eb-4de5-e123-a3053b585abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: i am excited learning about large language models\n",
            "Sentiment: Happy\n",
            "Probabilities: tensor([[0.2153, 0.7847]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load a sentiment analysis pipeline\n",
        "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# Define labels\n",
        "label_map = {\n",
        "    \"POSITIVE\": \"Happy\",\n",
        "    \"NEGATIVE\": \"Sad\"\n",
        "}\n",
        "\n",
        "# Input sentence\n",
        "sentence = \"i love large language models\"\n",
        "\n",
        "# Classify the sentence\n",
        "result = classifier(sentence)[0]\n",
        "predicted_label = label_map.get(result['label'], \"Unknown\")\n",
        "\n",
        "# Print result\n",
        "print(f\"Sentence: {sentence}\")\n",
        "print(f\"Predicted Sentiment: {predicted_label}\")\n",
        "print(f\"Confidence Score: {result['score']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7wO0bGacOBl",
        "outputId": "1948fb91-8a47-4e5f-d9e1-a19364e9a028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: i love large language models\n",
            "Predicted Sentiment: Happy\n",
            "Confidence Score: 0.9996\n"
          ]
        }
      ]
    }
  ]
}